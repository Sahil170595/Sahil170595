# Chimeraforge Technical Reports

## Comprehensive LLM Performance Research & Cross-Language Analysis

This directory contains the complete research journey documenting LLM performance analysis, optimization strategies, multi-agent orchestration, and cross-language (Rust vs Python) performance evaluation in the Chimeraforge research project.

> **Note:** This is the **Chimeraforge** research repository. All technical reports are based on research conducted in this repository.

---

## üìä Research Journey Overview

### Phase 1: Single-Agent Foundation (TR108-TR109)

**Objective:** Establish baseline LLM performance and agent workflow optimization

- **TR108:** Single-agent LLM performance analysis (Python)
- **TR109:** Agent workflow optimization (Python)

### Phase 2: Multi-Agent Python Baseline (TR110)

**Objective:** Establish Python multi-agent performance baseline

- **TR110:** Concurrent multi-agent performance analysis (Python)

### Phase 3: Rust Single-Agent Implementation (TR111)

**Objective:** Port Python agents to Rust and validate single-agent performance

- **TR111:** Initial Rust agent (micro-benchmark) - **SUPERSEDED**
- **TR111_v2:** ‚úÖ **Production-grade Rust single-agent** (full workflow parity)

### Phase 4: Cross-Language Single-Agent Comparison (TR112)

**Objective:** Direct Rust vs Python single-agent performance comparison

- **TR112:** Initial comparison (flawed - used micro-benchmark) - **SUPERSEDED**
- **TR112_v2:** ‚úÖ **Comprehensive Rust vs Python comparison** (production-grade)

### Phase 5: Rust Multi-Agent Implementation (TR113-TR114)

**Objective:** Port multi-agent orchestration to Rust and compare to Python

- **TR113:** Rust multi-agent (single Ollama) - identified server contention issue
- **TR114:** Rust multi-agent (dual Ollama) - initial analysis - **SUPERSEDED**
- **TR114_v2:** ‚úÖ **Comprehensive Rust multi-agent** (dual Ollama, corrected statistics)

### Phase 6: Runtime Optimization (TR115)

**Objective:** Optimize Rust async runtime for multi-agent workloads

- **TR115:** Initial runtime analysis - **SUPERSEDED**
- **TR115_v2:** ‚úÖ **Definitive runtime optimization** (5 runtimes, 150 runs)

### Phase 7: Cross-Backend Inference Benchmarking (TR117)

**Objective:** Compare local-first inference backends and identify production baselines

- **TR117:** ‚úÖ **Cross-backend inference benchmark** (PyTorch eager/compile, Ollama; ONNX/TRT failures documented)

### Phase 8: ONNX Runtime + TensorRT Deep Dive (TR118)

**Objective:** Fix ONNX/TRT infrastructure and produce publishable, local-first results

- **TR118:** ‚úÖ **ONNX/TRT deep dive** (real ONNX export, real TRT engines, INT8 calibration, perplexity gates)

---

## üìã Technical Reports Index

### ‚úÖ **Current Production-Ready Reports (v2)**

| Report | Title | Status | Key Finding |
|--------|-------|--------|-------------|
| **TR108** | Single-Agent LLM Performance Analysis | ‚úÖ Complete | Optimal configs for single-agent inference |
| **TR109** | Agent Workflow Optimization | ‚úÖ Complete | GPU=60, CTX=512, TEMP=0.8 optimal for workflows |
| **TR110** | Concurrent Multi-Agent Performance (Python) | ‚úÖ Complete | 99.25% parallel efficiency achieved |
| **TR111_v2** | Rust Single-Agent Performance | ‚úÖ Complete | 114.54 tok/s baseline, 15.2% faster than Python |
| **TR112_v2** | Rust vs Python Comparison | ‚úÖ Complete | Rust: +15.2% throughput, -58% TTFT, -67% memory |
| **TR114_v2** | Rust Multi-Agent Performance | ‚úÖ Complete | 98.281% mean efficiency, 99.992% peak run |
| **TR115_v2** | Rust Runtime Optimization | ‚úÖ Complete | Tokio-default recommended (98.72% mean, 1.21pp œÉ) |
| **TR117** | Cross-Backend Inference Benchmark | ‚úÖ Complete | GPU-compile best mean; ONNX/TRT failures documented |
| **TR118** | ONNX Runtime vs TensorRT Deep Dive | ‚úÖ Complete | Publish-ready prefill benchmark + TRT INT8 calibration + perplexity gate |

### üìö **Historical Reports (Superseded)**

| Report | Status | Superseded By | Reason |
|--------|--------|---------------|--------|
| TR111 | ‚ùå Superseded | TR111_v2 | Micro-benchmark ‚Üí Full workflow |
| TR112 | ‚ùå Superseded | TR112_v2 | Flawed comparison methodology |
| TR114 | ‚ùå Superseded | TR114_v2 | Incorrect statistics (97.5% ‚Üí 98.281%) |
| TR115 | ‚ùå Superseded | TR115_v2 | Incomplete data analysis (30 ‚Üí 150 runs) |

---

## üéØ Key Research Findings

### **Single-Agent Performance (TR111_v2, TR112_v2)**

**Rust Advantages:**

- **Throughput:** 114.54 tok/s vs Python 99.34 tok/s (**+15.2%**)
- **TTFT (cold):** 603ms vs Python 1437ms (**-58%**)
- **Memory:** ~75 MB vs Python ~250 MB (**-67%**)
- **Startup:** 0.2s vs Python 1.5s (**-83%**)
- **Consistency:** 2.6% CV vs Python 4.8% CV (**46% more consistent**)

**Verdict:** Rust dominates single-agent performance across all metrics.

### **Multi-Agent Performance (TR110, TR114_v2)**

**Python Baseline (TR110):**

- **Peak Config Efficiency:** 99.25% (homogeneous Chimera)
- **Mean Efficiency:** 95.8% (all 150 runs)
- **Contention Rate:** 10-15%

**Rust Performance (TR114_v2):**

- **Peak Config Efficiency:** 99.396% (chimera-hetero test011)
- **Peak Single Run:** 99.992% (chimera-homo test108)
- **Mean Efficiency:** 98.281% (all 135 runs) - **+2.48pp vs Python**
- **Contention Rate:** 0.74% - **-10-14pp vs Python**

**Verdict:** Rust **exceeds** Python in multi-agent scenarios (+2.48pp mean, +0.15pp peak config).

### **Runtime Optimization (TR115_v2)**

**Runtime Ranking (By Consistency):**

1. **Tokio-default:** 98.72% mean, 1.21pp œÉ üèÜ **RECOMMENDED**
2. **Smol-1KB:** 98.61% mean, 1.32pp œÉ ‚úÖ **Alternative (smaller binary)**
3. **Tokio-localset:** 97.95% mean, 4.03pp œÉ ‚ö†Ô∏è **Unstable (18.96pp range)**
4. **Smol:** 97.72% mean, 4.87pp œÉ ‚ùå **Pathological failures (72.80% min)**
5. **Async-std:** 50.00% ‚ùå **Catastrophic (Tokio bridge conflict)**

**Verdict:** Use **standard Tokio** (`#[tokio::main]`) - no custom configuration needed.

---

## üìà Performance Summary Matrix

### **Single-Agent Comparison (TR112_v2)**

| Metric | Python | Rust | Rust Advantage |
|--------|--------|------|----------------|
| **Throughput** | 99.34 tok/s | 114.54 tok/s | **+15.2%** |
| **TTFT (cold)** | 1437 ms | 603 ms | **-58.0%** |
| **Memory** | ~250 MB | ~75 MB | **-67%** |
| **Startup** | 1.5s | 0.2s | **-83%** |
| **CV (throughput)** | 4.8% | 2.6% | **-46% (more consistent)** |

### **Multi-Agent Comparison (TR110 vs TR114_v2)**

| Metric | Python (TR110) | Rust (TR114_v2) | Rust Advantage |
|--------|---------------|-----------------|----------------|
| **Peak Config Avg** | 99.25% | 99.396% | **+0.15pp** |
| **Peak Single Run** | 99.25% | 99.992% | **+0.74pp** |
| **Mean Efficiency** | 95.8% | 98.281% | **+2.48pp** |
| **Median Efficiency** | ~96.5% | 98.6% | **+2.1pp** |
| **StdDev** | 7.4pp | 4.9pp | **-2.5pp (more stable)** |
| **Contention Rate** | 10-15% | 0.74% | **-10-14pp** |

### **Runtime Performance (TR115_v2)**

| Runtime | Peak (%) | Mean (%) | StdDev (pp) | Min (%) | Recommendation |
|---------|----------|----------|-------------|---------|----------------|
| **Tokio-default** | 99.89 | **98.72** | **1.21** | 94.80 | ‚úÖ **Production** |
| **Smol-1KB** | 99.94 | 98.61 | 1.32 | 94.98 | ‚úÖ **Small binary** |
| **Tokio-localset** | 99.99 | 97.95 | 4.03 | 81.03 | ‚ö†Ô∏è **Unstable** |
| **Smol** | 99.87 | 97.72 | 4.87 | 72.80 | ‚ùå **Avoid** |
| **Async-std** | 50.00 | 50.00 | 0.00 | 50.00 | ‚ùå **Unusable** |

---

## üî¨ Report Details

### **TR108: Single-Agent LLM Performance Analysis**

**File:** `Technical_Report_108.md`

- **Focus:** Comprehensive LLM performance benchmarking and optimization
- **Models:** gemma3:latest, llama3.1:8b-instruct variants
- **Hardware:** NVIDIA RTX 4080 (12GB VRAM), i9-13980HX
- **Test Matrix:** 150+ benchmark runs across parameter sweeps
- **Key Findings:** Optimal configurations for single-agent inference
- **Status:** ‚úÖ Complete (Publication-ready)

### **TR109: Agent Workflow Optimization**

**File:** `Technical_Report_109.md`

- **Focus:** Agent workflow performance vs single-inference optimization
- **Methodology:** Process isolation, forced cold starts, statistical validation
- **Key Findings:** Agent tasks require different optimization than single-inference
- **Optimal Config:** GPU=60, CTX=512, TEMP=0.8 for agent workflows
- **Quality Analysis:** Automated scoring methodology for report quality
- **Status:** ‚úÖ Complete (Publication-ready)

### **TR110: Concurrent Multi-Agent Performance Analysis (Python)**

**File:** `Technical_Report_110.md`

- **Focus:** Parallel agent execution with resource coordination
- **Test Matrix:** 30 configurations √ó 5 runs = 150 benchmark runs
- **Key Findings:** 99.25% parallel efficiency achieved with homogeneous Chimera agents
- **Scenarios:** Baseline vs Chimera, Heterogeneous, Homogeneous configurations
- **Resource Analysis:** VRAM utilization, memory bandwidth saturation, contention patterns
- **Status:** ‚úÖ Complete (Publication-ready)

### **TR111_v2: Rust Single-Agent Performance Analysis**

**File:** `Technical_Report_111_v2.md`

- **Focus:** Comprehensive Rust agent workflow performance with full Python parity
- **Test Matrix:** 19 configurations √ó 3 runs = 57 benchmark runs
- **Key Findings:**
  - Baseline: 114.54 tok/s (15.2% faster than Python)
  - TTFT: 547-1354ms range (high variance, context-dependent)
  - Optimal: `gpu60_ctx256_temp0p6` (115.94 tok/s)
- **Critical Discovery:** TTFT shows 150√ó more variation than throughput
- **Status:** ‚úÖ Complete (Supersedes TR111)

### **TR112_v2: Rust vs Python Agent Performance Comparison**

**File:** `Technical_Report_112_v2.md`

- **Focus:** Cross-language comprehensive comparison with workflow parity
- **Test Matrix:** 37 configurations (19 Rust + 18 Python), 111 total runs
- **Key Findings:**
  - Rust: +15.2% throughput, -58% TTFT, -67% memory, -83% startup
  - Rust: 46% more consistent (2.6% vs 4.8% CV)
  - Business Impact: ~$3,040/year savings, 20-month break-even
- **Status:** ‚úÖ Complete (Supersedes TR112)

### **TR113: Rust Multi-Agent Initial Analysis**

**File:** `Technical_Report_113.md`

- **Focus:** First Rust multi-agent implementation (single Ollama instance)
- **Key Finding:** 82.2% peak efficiency, 63% contention rate
- **Critical Discovery:** Server-level serialization bottleneck identified
- **Recommendation:** Dual Ollama architecture required
- **Status:** ‚úÖ Complete (Historical - led to TR114)

### **TR114_v2: Rust Concurrent Multi-Agent Performance**

**File:** `Technical_Report_114_v2.md`

- **Focus:** Comprehensive Rust multi-agent with dual Ollama architecture
- **Test Matrix:** 27 configurations √ó 5 runs = 135 benchmark runs
- **Key Findings:**
  - Peak single run: 99.992% (test108)
  - Best config avg: 99.396% (test011 chimera-hetero)
  - Mean efficiency: 98.281% (+2.48pp vs Python)
  - Contention rate: 0.74% (-10-14pp vs Python)
- **Critical Discovery:** Rust **exceeds** Python in multi-agent scenarios
- **Status:** ‚úÖ Complete (Supersedes TR114)

### **TR115_v2: Rust Async Runtime Performance Deep Dive**

**File:** `Technical_Report_115_v2.md`

- **Focus:** Comprehensive multi-runtime analysis for multi-agent workloads
- **Test Matrix:** 5 runtimes √ó 6 configs √ó 5 runs = 150 benchmark runs
- **Key Findings:**
  - All 4 working runtimes achieve ~100% peak (99.87-99.99%)
  - Consistency matters more: Tokio-default (1.21pp œÉ) recommended
  - Async-std unusable (50% efficiency, Tokio bridge conflict)
  - Smol has pathological failures (72.80% min efficiency)
- **Production Recommendation:** Use standard `#[tokio::main]` - no custom config needed
- **Status:** ‚úÖ Complete (Supersedes TR115)

---

## üéì Research Evolution & Key Insights

### **The Journey: From Python Baseline to Rust Excellence**

1. **TR108-TR109 (Python Foundation):** Established optimal single-agent and workflow configurations
2. **TR110 (Python Multi-Agent):** Achieved 99.25% parallel efficiency baseline
3. **TR111_v2 (Rust Single-Agent):** Discovered Rust's 15.2% throughput advantage
4. **TR112_v2 (Cross-Language):** Quantified Rust's comprehensive advantages (performance, memory, startup)
5. **TR113 (Rust Multi-Agent v1):** Identified server contention bottleneck (single Ollama)
6. **TR114_v2 (Rust Multi-Agent v2):** Proved Rust **exceeds** Python in multi-agent (+2.48pp mean)
7. **TR115_v2 (Runtime Optimization):** Established Tokio-default as optimal runtime

### **Critical Discoveries**

1. **Single-Agent:** Rust is **15.2% faster** than Python (TR112_v2)
2. **Multi-Agent:** Rust **exceeds** Python by +2.48pp mean efficiency (TR114_v2)
3. **Runtime:** Standard Tokio achieves 98.72% mean with 1.21pp œÉ (TR115_v2)
4. **Architecture:** Dual Ollama **mandatory** for multi-agent (reduces contention 63% ‚Üí 0.74%)
5. **Consistency:** Rust's lower variance (4.9pp vs 7.4pp) provides production reliability

### **The "Paradox" That Wasn't**

**Initial Hypothesis (TR113/TR114):** Rust's single-agent advantage would disappear in multi-agent scenarios due to coordination overhead.

**Actual Reality (TR114_v2):** Rust's advantages **carry over** to multi-agent:

- Single-agent: +15.2% throughput
- Multi-agent: +2.48pp mean efficiency, +0.15pp peak config
- **Conclusion:** No paradox - Rust maintains and extends advantages

---

## üöÄ Production Recommendations

### **Single-Agent Deployment**

**Choose Rust if:**

- ‚úÖ Production reliability required
- ‚úÖ Resource efficiency critical (67% less memory)
- ‚úÖ Fast startup needed (83% faster)
- ‚úÖ Consistent performance valued (46% lower variance)

**Choose Python if:**

- ‚úÖ Rapid prototyping needed
- ‚úÖ Development velocity prioritized
- ‚úÖ Ecosystem richness required

**Verdict:** **Rust for production** (15% faster, 67% less memory, 83% faster startup)

### **Multi-Agent Deployment**

**Architecture:**

- ‚úÖ **Dual Ollama instances** (mandatory - eliminates server contention)
- ‚úÖ **Heterogeneous configs** optimal (asymmetric GPU allocation)
- ‚úÖ **Tokio-default runtime** (best consistency: 1.21pp œÉ)

**Configuration:**

- **Best Config (TR114_v2):** GPU=120/140, CTX=512/1024 (test011) ‚Üí 99.396% efficiency
- **Balanced Config:** GPU=80, CTX=1024 (test004) ‚Üí 98.984% efficiency
- **Avoid:** GPU=120 in baseline-vs-chimera (test005: 91.60% with contention)

**Verdict:** **Rust multi-agent** (98.281% mean vs Python 95.8%, 0.74% contention vs 10-15%)

### **Runtime Selection (TR115_v2)**

**Production:**

```rust
// Use standard Tokio - no custom configuration needed
#[tokio::main]
async fn main() {
    let (r1, r2) = tokio::join!(agent_a(), agent_b());
}
```

**Why:**

- ‚úÖ Highest consistency: 1.21pp œÉ (vs 4.03pp for localset)
- ‚úÖ Best mean efficiency: 98.72% (vs 97.95% for localset)
- ‚úÖ Simplest deployment: No custom runtime configuration
- ‚úÖ Best ecosystem: Native reqwest, no bridges

**Alternatives:**

- **Smol-1KB:** If binary size <5MB critical (98.61% mean, 1.32pp œÉ, -0.11pp loss acceptable)
- **Never use:** Async-std (50% efficiency), Smol (pathological failures)

---

## üí∞ Business Impact Summary

### **Infrastructure Savings (TR112_v2)**

**Single-Agent:**

- Memory: 67% reduction (75 MB vs 250 MB)
- Startup: 83% faster (0.2s vs 1.5s)
- **Cost:** ~$3,040/year savings at 1M requests/month
- **Break-even:** 20 months ($5k dev overhead)

### **Multi-Agent Advantages (TR114_v2)**

**Performance:**

- Mean efficiency: +2.48pp (98.281% vs 95.8%)
- Contention rate: -10-14pp (0.74% vs 10-15%)
- Consistency: -2.5pp StdDev (4.9pp vs 7.4pp)

**Cost:**

- 50% lower infrastructure cost (67% less memory per agent)
- 3√ó concurrent capacity (lower memory footprint)
- Reduced contention = fewer failed requests

### **Runtime Optimization (TR115_v2)**

**Impact:**

- Runtime choice: Marginal (<1% between best options)
- **Async-std cost:** 50% efficiency = **2√ó infrastructure cost** (avoid!)
- **Tokio-default cost:** Same as Python (both ~99% efficiency)

**Strategic Insight:** Standard Tokio requires zero custom configuration, achieving Python parity with Rust's resource advantages.

---

## üìÅ Repository Structure

```
PublishReady/reports/
‚îú‚îÄ‚îÄ README.md (this file)
‚îÇ
‚îú‚îÄ‚îÄ ‚úÖ Production-Ready Reports (v2)
‚îÇ   ‚îú‚îÄ‚îÄ Technical_Report_108.md - Single-agent LLM performance (Python)
‚îÇ   ‚îú‚îÄ‚îÄ Technical_Report_109.md - Agent workflow optimization (Python)
‚îÇ   ‚îú‚îÄ‚îÄ Technical_Report_110.md - Multi-agent performance (Python)
‚îÇ   ‚îú‚îÄ‚îÄ Technical_Report_111_v2.md - Rust single-agent performance
‚îÇ   ‚îú‚îÄ‚îÄ Technical_Report_112_v2.md - Rust vs Python comparison
‚îÇ   ‚îú‚îÄ‚îÄ Technical_Report_114_v2.md - Rust multi-agent performance
‚îÇ   ‚îî‚îÄ‚îÄ Technical_Report_115_v2.md - Rust runtime optimization
‚îÇ
‚îú‚îÄ‚îÄ üìö Historical Reports (Superseded)
‚îÇ   ‚îú‚îÄ‚îÄ Technical_Report_111.md - Initial Rust (micro-benchmark)
‚îÇ   ‚îú‚îÄ‚îÄ Technical_Report_112.md - Flawed comparison
‚îÇ   ‚îú‚îÄ‚îÄ Technical_Report_113.md - Rust multi-agent (single Ollama)
‚îÇ   ‚îú‚îÄ‚îÄ Technical_Report_114.md - Rust multi-agent (incorrect stats)
‚îÇ   ‚îî‚îÄ‚îÄ Technical_Report_115.md - Incomplete runtime analysis
‚îÇ
‚îî‚îÄ‚îÄ üìä Model Benchmarks
    ‚îî‚îÄ‚îÄ gemma3/
        ‚îî‚îÄ‚îÄ Gemma3_Benchmark_Report.md
```

---

## üîó Report Relationships

```
TR108 (Python Single-Agent)
    ‚Üì
TR109 (Python Workflow Optimization)
    ‚Üì
TR110 (Python Multi-Agent Baseline)
    ‚Üì
TR111_v2 (Rust Single-Agent) ‚îÄ‚îÄ‚Üí TR112_v2 (Rust vs Python)
    ‚Üì                                    ‚Üì
TR113 (Rust Multi-Agent v1)      TR114_v2 (Rust Multi-Agent v2)
    ‚Üì                                    ‚Üì
TR114_v2 (Dual Ollama)            TR115_v2 (Runtime Optimization)
```

**Key Dependencies:**

- TR111_v2 ‚Üí TR112_v2 (single-agent comparison)
- TR110 ‚Üí TR114_v2 (multi-agent comparison)
- TR111_v2/TR112_v2/TR114_v2 ‚Üí TR115_v2 (baseline references)
- TR113 ‚Üí TR114_v2 (identified dual Ollama requirement)

---

## üìñ Quick Reference

### **Best Configurations**

**Single-Agent (TR111_v2):**

- **Optimal:** `gpu60_ctx256_temp0p6` (115.94 tok/s)
- **Baseline:** Ollama defaults (114.54 tok/s)

**Multi-Agent (TR114_v2):**

- **Best Config:** GPU=120/140, CTX=512/1024 (test011) ‚Üí 99.396% efficiency
- **Balanced:** GPU=80, CTX=1024 (test004) ‚Üí 98.984% efficiency

**Runtime (TR115_v2):**

- **Production:** Tokio-default (`#[tokio::main]`)
- **Small Binary:** Smol-1KB (if size critical)

### **Performance Targets**

**Single-Agent:**

- Rust: 114.54 tok/s baseline, 115.94 tok/s optimal
- Python: 99.34 tok/s baseline

**Multi-Agent:**

- Rust: 98.281% mean, 99.396% peak config, 99.992% peak run
- Python: 95.8% mean, 99.25% peak config

**Runtime:**

- Tokio-default: 98.72% mean, 1.21pp œÉ (recommended)
- Smol-1KB: 98.61% mean, 1.32pp œÉ (alternative)

---

## üéØ Research Questions Answered

1. **Q: Is Rust faster than Python for LLM inference?**  
   **A: Yes - 15.2% faster throughput, 58% faster TTFT, 67% less memory (TR112_v2)**

2. **Q: Does Rust's single-agent advantage carry over to multi-agent?**  
   **A: Yes - Rust exceeds Python by +2.48pp mean efficiency (TR114_v2)**

3. **Q: Which Rust async runtime is optimal for multi-agent workloads?**  
   **A: Tokio-default - 98.72% mean, 1.21pp œÉ (best consistency) (TR115_v2)**

4. **Q: Is dual Ollama architecture necessary?**  
   **A: Yes - Reduces contention from 63% to 0.74% (TR113 ‚Üí TR114_v2)**

5. **Q: What is the optimal multi-agent configuration?**  
   **A: Heterogeneous GPU allocation (120/140) with asymmetric context (512/1024) ‚Üí 99.396% efficiency (TR114_v2)**

---

## üìä Statistical Validation

All reports include:

- ‚úÖ **Statistical rigor:** Mean, median, stddev, percentiles, CV
- ‚úÖ **Multiple runs:** 3-5 runs per configuration for confidence
- ‚úÖ **Comprehensive coverage:** 19-37 configurations per report
- ‚úÖ **Cross-validation:** Results validated across multiple reports
- ‚úÖ **Reproducibility:** Full methodology and data sources documented

**Total Benchmark Runs:**

- TR108: 150+ runs
- TR109: 90 runs
- TR110: 150 runs
- TR111_v2: 57 runs
- TR112_v2: 111 runs
- TR114_v2: 135 runs
- TR115_v2: 150 runs
- **Total: 843+ benchmark runs** across all reports

---

## üöÄ Getting Started

### **For Researchers**

1. Start with **TR108** (Python single-agent baseline)
2. Review **TR109** (workflow optimization methodology)
3. Study **TR110** (Python multi-agent baseline)
4. Compare **TR112_v2** (Rust vs Python single-agent)
5. Analyze **TR114_v2** (Rust multi-agent performance)
6. Reference **TR115_v2** (runtime optimization guidance)

### **For Engineers**

1. **Single-Agent:** Read **TR112_v2** for Rust vs Python comparison
2. **Multi-Agent:** Read **TR114_v2** for deployment guidance
3. **Runtime:** Read **TR115_v2** for production recommendations
4. **Configuration:** Use best configs from TR111_v2 (single) and TR114_v2 (multi)

### **For Decision Makers**

1. **Executive Summary:** Review "Key Findings" sections in each report
2. **Business Impact:** See "Business Impact" sections in TR112_v2, TR114_v2
3. **Recommendations:** See "Production Recommendations" in this README
4. **Cost Analysis:** Review break-even analysis in TR112_v2

---

## üìù Report Status Legend

- ‚úÖ **Complete (Publication-ready):** Fully validated, production-grade analysis
- üìö **Historical (Superseded):** Replaced by v2 with corrected methodology/data
- üî¨ **In Progress:** Currently being developed

---

**Last Updated:** 2025-12-12  
**Repository:** Chimeraforge (Research)  
**Maintainer:** Chimeraforge Research Team  
**Total Reports:** 12 (7 production-ready, 5 historical)  
**Total Benchmark Runs:** 843+ across all reports
